{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Denis Alonso\n",
    "\n",
    "Nome: Felipe Menke\n",
    "\n",
    "Nome: Gabriel Correia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Atenção: <br> $\\quad$* Serão permitidos grupos de até 3 pessoas, mas com uma rubrica mais exigente. <br> $\\quad$* Veja RUBRICA na última página do arquivo PDF que traz o enunciado do Proejto 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\lipem\\OneDrive\\Documentos\\GitHub\\PyGAME\\Projeto1-Cdados-Insper\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Carregando a base de dados com as mensagens dos seus arquivos. <br> Tire o `#` do início da linha de código condizente ao caso escolhido para o projeto 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE SEU PROJETO USA OS DADOS SOBRE \"Airline Passenger Reviews\"\n",
    "train = pd.read_csv('dados_treino_ate_TRIO_FelipeMenke.csv')\n",
    "test = pd.read_csv('dados_teste_ate_TRIO_FelipeMenke.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE SEU PROJETO USA OS DADOS SOBRE \"ChatGPT Classification\"\n",
    "#train = pd.read_csv('dados_treino_so_DUPLA_'+nome+'.csv')\n",
    "#test = pd.read_csv('dados_teste_so_DUPLA_'+nome+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singapore to Jakarta. 9 years since I last to...</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Norwegian Long Haul. OSL-LGW. Flight DY1310. 1...</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guangzhou to Paris. I have paid for inflight...</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vientiane to Melbourne via Bangkok. A very en...</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I travelled Manchester - Sydney return on 777-...</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review    Target\n",
       "0   Singapore to Jakarta. 9 years since I last to...   Passive\n",
       "1  Norwegian Long Haul. OSL-LGW. Flight DY1310. 1...  Promoter\n",
       "2    Guangzhou to Paris. I have paid for inflight...  Promoter\n",
       "3   Vientiane to Melbourne via Bangkok. A very en...  Promoter\n",
       "4  I travelled Manchester - Sydney return on 777-...   Passive"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budapest to Warsaw. The ground crew was very ...</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bergerac to Stansted. Just come off a particul...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRU-LIS. Flight left a few minutes late aircra...</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fleet of A319 and A320 in this route. Fast che...</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 Nov Houston-Doha QR714 and 15 Nov Doha-Houst...</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     Target\n",
       "0   Budapest to Warsaw. The ground crew was very ...    Passive\n",
       "1  Bergerac to Stansted. Just come off a particul...  Detractor\n",
       "2  BRU-LIS. Flight left a few minutes late aircra...   Promoter\n",
       "3  Fleet of A319 and A320 in this route. Fast che...    Passive\n",
       "4  4 Nov Houston-Doha QR714 and 15 Nov Doha-Houst...    Passive"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador Automático (Boot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu assunto e o contexto referente aos rótulos cujas mensagens (ou reviews) deverão ser classificadas.\n",
    "\n",
    "ESCREVA AQUI..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Montando SEU Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para limpar o texto\n",
    "\n",
    "\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')    \n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    punctuation = '[´\"!-.:?;$'']' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    \n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Todas as Avaliações**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descobrindo a quantidade total de palavras\n",
    "dic_total = train.loc[:, \"Review\"]  \n",
    "palavras_totais = dic_total.tolist()  \n",
    "palavras_totais = \" \".join(palavras_totais)  \n",
    "palavras_totais = cleanup(palavras_totais).lower()  \n",
    "palavras_totais = palavras_totais.split()  \n",
    "palavras_totais = pd.Series(palavras_totais)  \n",
    "qtd_palavras_totais = palavras_totais.value_counts()  \n",
    "qtd_palavras_totais = qtd_palavras_totais.sum() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dados - Avaliações Perfil Passivo**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASSIVO\n",
    "\n",
    "dic_passivos = train.loc[train[\"Target\"]==\"Passive\",\"Review\"]\n",
    "#Transformando em Lista\n",
    "frases_passivos = dic_passivos.tolist()\n",
    "\n",
    "#Juntando as frases,Limpando (caracteres especiais, e diminuindo as letras)\n",
    "frases_passivos = \" \".join(frases_passivos)\n",
    "frases_passivos = cleanup(frases_passivos).lower()\n",
    "frases_passivos = frases_passivos.split()\n",
    "\n",
    "#Probabilidade de ser Passivo\n",
    "qtd_palavras_passivos = pd.Series(frases_passivos).value_counts()\n",
    "qtd_palavras_passivos = qtd_palavras_passivos.sum()\n",
    "\n",
    "Prob_Passivo = qtd_palavras_passivos/qtd_palavras_totais\n",
    "\n",
    "#Criando Frequencia Relativa das Palavras\n",
    "\n",
    "freq_rel_passivos = pd.Series(frases_passivos).value_counts(True)\n",
    "freq_abs_passivos = pd.Series(frases_passivos).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dados - Avaliações Perfil Detrator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DETRACTOR\n",
    "\n",
    "dic_detrator = train.loc[train[\"Target\"]==\"Detractor\",\"Review\"]\n",
    "\n",
    "#Transformando em Lista\n",
    "frases_detractor = dic_detrator.tolist()\n",
    "#Juntando as frases,Limpando (caracteres especiais, e diminuindo as letras)\n",
    "frases_detractor = \" \".join(frases_detractor)\n",
    "frases_detractor = cleanup(frases_detractor).lower()\n",
    "frases_detractor = frases_detractor.split()\n",
    "\n",
    "#Probabilidade de ser Detrator\n",
    "qtd_palavras_detrator = pd.Series(frases_detractor).value_counts()\n",
    "qtd_palavras_detrator = qtd_palavras_detrator.sum()\n",
    "\n",
    "Prob_Detrator = qtd_palavras_detrator/qtd_palavras_totais\n",
    "\n",
    "#Criando Frequencia Relativa das Palavras\n",
    "\n",
    "freq_rel_detrator = pd.Series(frases_detractor).value_counts(True)\n",
    "freq_abs_detrator = pd.Series(frases_detractor).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dados - Avaliações Perfil Promoter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the         0.049208\n",
      "and         0.037813\n",
      "to          0.029852\n",
      "was         0.026083\n",
      "a           0.021977\n",
      "              ...   \n",
      "737800ng    0.000011\n",
      "sep/13      0.000011\n",
      "eilna       0.000011\n",
      "787800      0.000011\n",
      "dy1310      0.000011\n",
      "Name: proportion, Length: 6755, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#PROMOTER\n",
    "\n",
    "dic_promoter = train.loc[train[\"Target\"]==\"Promoter\",\"Review\"]\n",
    "\n",
    "#Transformando em Lista\n",
    "frases_promoter = dic_promoter.tolist()\n",
    "\n",
    "#Juntando as frases,Limpando (caracteres especiais, e diminuindo as letras)\n",
    "frases_promoter = \" \".join(frases_promoter)\n",
    "frases_promoter = cleanup(frases_promoter).lower()\n",
    "frases_promoter = frases_promoter.split()\n",
    "\n",
    "#Probabilidade de ser Detrator\n",
    "qtd_palavras_promoter = pd.Series(frases_promoter).value_counts()\n",
    "qtd_palavras_promoter = qtd_palavras_promoter.sum()\n",
    "\n",
    "Prob_Promoter = qtd_palavras_promoter/qtd_palavras_totais\n",
    "\n",
    "#Criando Frequencia Relativa das Palavras\n",
    "\n",
    "freq_rel_promoter = pd.Series(frases_promoter).value_counts(True)\n",
    "freq_abs_promoter = pd.Series(frases_promoter).value_counts()\n",
    "print(freq_rel_promoter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0462209618399587e-54 3.219849442065111e-60 2.257408963327774e-55\n",
      "7.403194687774474e-67 9.305112690041796e-97 3.232435161411163e-78\n",
      "2.7155358370033393e-14 1.4574855236932163e-11 1.6944947646151867e-09\n",
      "2.6483508711701077e-31 1.4651284931125773e-33 9.540463421346504e-28\n",
      "9.739669244639226e-78 4.443774022853025e-91 2.4768172024959833e-79\n",
      "8.713213916802442e-16 1.4869538391628585e-14 2.3963057350770124e-13\n",
      "4.567677423525511e-18 9.188952325513231e-21 4.317070037863562e-18\n",
      "4.931266746840487e-38 1.0725115915360185e-46 2.3361842942249474e-33\n",
      "6.68513160538975e-29 4.334230683933559e-43 1.4232487688038102e-33\n",
      "1.7613437061689142e-22 2.160516733982036e-28 1.7589989922695e-24\n",
      "1.7867219626109118e-83 1.2827256467279345e-112 6.416915679402125e-97\n",
      "7.931470674886446e-24 5.81503689971709e-27 2.7554455751596875e-22\n",
      "1.525094919065475e-39 3.336220111809266e-40 1.0605759107826951e-36\n",
      "5.976443885744886e-35 3.915598232065954e-57 5.163952563631338e-53\n",
      "4.13447305101389e-48 8.481560450821225e-52 3.1197756013908697e-46\n",
      "5.318984125101263e-52 5.421004642378893e-77 4.66131718948617e-64\n",
      "9.934665420198694e-41 6.087369474580362e-49 2.3391720983816525e-41\n",
      "5.259375175563429e-88 5.773012678272265e-107 1.010099421988034e-91\n",
      "1.2964926800161434e-30 5.587853098402385e-41 1.8518588611154355e-36\n",
      "3.52875411514709e-11 2.5362422964604138e-31 1.5512709764310284e-24\n",
      "9.019280412998402e-117 6.444090516094548e-208 7.006281512079673e-175\n",
      "1.7762716352792337e-165 3.114427382226969e-229 3.0548511584314597e-197\n",
      "5.342056314558607e-74 4.479816582833849e-92 3.270973633314196e-79\n",
      "1.2965273680776603e-65 5.259292388913953e-73 1.1233977274736863e-66\n",
      "1.494980198524555e-39 4.9984457717939714e-40 3.4960779936803156e-34\n",
      "1.9079036509659493e-28 1.4354188545667833e-29 3.3701044560271755e-25\n",
      "2.2902657321538963e-142 1.6872617262413472e-155 1.5240673808221536e-135\n",
      "1.664578630693027e-44 4.853827032156545e-57 3.721939927860729e-51\n",
      "2.8683045641233566e-33 4.788966316516283e-34 2.507069531783636e-27\n",
      "7.500894097843262e-47 9.363903473835754e-63 1.3875814551030453e-53\n",
      "5.899225439864192e-131 1.6709806811307366e-162 4.492576187585441e-133\n",
      "2.967988294844372e-41 7.100086816335228e-96 2.090890352764693e-71\n",
      "4.593627684441681e-119 5.192100587242529e-152 1.1354062756640204e-124\n",
      "4.503026088739083e-44 8.07595907060398e-74 5.21499054141755e-64\n",
      "1.9525509134198938e-16 5.0934537974622515e-30 1.3416172245067667e-25\n",
      "1.1250747659336943e-24 4.513633606394497e-47 1.969538970381507e-37\n",
      "3.287700554864031e-73 9.623050439237285e-92 9.632938079016198e-78\n",
      "2.0558032565936506e-18 1.3911768238787802e-17 2.6847175788872715e-15\n",
      "1.6067239986705246e-71 5.1364257224401877e-67 8.242673035788607e-61\n",
      "2.990860985931461e-78 1.0467422136694254e-92 6.020081847252966e-78\n",
      "4.3265536200571676e-244 3.38192208288866e-309 5.844395308075084e-262\n",
      "2.2530875118883098e-72 1.101492729212137e-88 3.669332021173248e-78\n",
      "1.3756105853887595e-43 1.1682390641524903e-68 2.6253736462778933e-58\n",
      "2.202180316586085e-19 7.940316230170364e-23 1.0769502613571645e-18\n",
      "7.375587923020939e-52 2.1510646932033824e-56 9.249332645231941e-51\n",
      "2.8584908418614117e-51 1.8540883772726285e-82 1.2606160885599937e-69\n",
      "9.990625612424382e-24 4.801178183737661e-16 6.60627960862979e-17\n",
      "3.490517143692845e-09 1.754647551323344e-11 2.66311175339968e-08\n",
      "2.6542208445361694e-51 2.1214832204635787e-113 8.607381220504654e-90\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 31\u001b[0m\n\u001b[0;32m     27\u001b[0m     probPromoterdadoFrase \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(qtd_palavras_promoter \u001b[38;5;241m+\u001b[39m qtd_palavras_totais))  \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m palavra \u001b[38;5;129;01min\u001b[39;00m frases_detractor:\n\u001b[1;32m---> 31\u001b[0m     probDetratordadoFrase \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mfreq_abs_detrator\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpalavra\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m(qtd_palavras_detrator \u001b[38;5;241m+\u001b[39m qtd_palavras_totais)   \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     probDetratordadoFrase \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(qtd_palavras_detrator \u001b[38;5;241m+\u001b[39m qtd_palavras_totais)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\series.py:1096\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m-> 1096\u001b[0m     \u001b[43mcheck_dict_or_set_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1097\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mEllipsis\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:2765\u001b[0m, in \u001b[0;36mcheck_dict_or_set_indexers\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m   2753\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2754\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   2755\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   2756\u001b[0m \u001b[38;5;124;03m    bool\u001b[39;00m\n\u001b[0;32m   2757\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m   2759\u001b[0m         obj\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (obj\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   2762\u001b[0m     )\n\u001b[1;32m-> 2765\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_dict_or_set_indexers\u001b[39m(key) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2766\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2767\u001b[0m \u001b[38;5;124;03m    Check if the indexer is or contains a dict or set, which is no longer allowed.\u001b[39;00m\n\u001b[0;32m   2768\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2770\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mset\u001b[39m)\n\u001b[0;32m   2771\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m   2772\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mset\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[0;32m   2773\u001b[0m     ):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##Codigo da suavização de Laplace\n",
    "\n",
    "dic_final = {}\n",
    "Target_test = test.loc[:, \"Target\"]\n",
    "Review_test = test.loc[:, \"Review\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(test)):\n",
    "    tipo = Target_test.iloc[i]  \n",
    "    frase = cleanup(Review_test.iloc[i]).lower().strip()\n",
    "    frase = \" \".join(frase.split())  \n",
    "\n",
    "\n",
    "    probDetratordadoFrase = 1\n",
    "    probPassivodadoFrase = 1\n",
    "    probPromoterdadoFrase = 1\n",
    "\n",
    "    for palavra in frase.split():\n",
    "        palavra = palavra.lower().strip()\n",
    "\n",
    "\n",
    "        if palavra in frases_promoter:\n",
    "            probPromoterdadoFrase *= (freq_abs_promoter[palavra]+ 1)/(qtd_palavras_promoter + qtd_palavras_totais)  * 1000\n",
    "        else:\n",
    "            probPromoterdadoFrase *=(1/(qtd_palavras_promoter + qtd_palavras_totais))  * 1000\n",
    "\n",
    "            \n",
    "        if palavra in frases_detractor:\n",
    "            probDetratordadoFrase *= (freq_abs_detrator[palavra]+ 1)/(qtd_palavras_detrator + qtd_palavras_totais)   * 1000\n",
    "        else:\n",
    "            probDetratordadoFrase *= (1/(qtd_palavras_detrator + qtd_palavras_totais)) * 1000\n",
    "\n",
    "        if palavra in frases_passivos:\n",
    "            probPassivodadoFrase *= (freq_abs_passivos[palavra]+ 1)/(qtd_palavras_passivos + qtd_palavras_totais)   * 1000\n",
    "        else:\n",
    "            probPassivodadoFrase *= (1/(qtd_palavras_passivos + qtd_palavras_totais))  * 1000\n",
    "\n",
    "    maior = max(probDetratordadoFrase, probPromoterdadoFrase, probPassivodadoFrase)\n",
    "    print( probDetratordadoFrase, probPromoterdadoFrase, probPassivodadoFrase)\n",
    "\n",
    "    if maior == probDetratordadoFrase:\n",
    "        final = \"Detractor\"\n",
    "    elif maior == probPromoterdadoFrase:\n",
    "        final = \"Promoter\"\n",
    "    else:\n",
    "        final = \"Passive\"\n",
    "\n",
    "    dic_final[i] = (tipo, final)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df_resultado = pd.DataFrame.from_dict(dic_final, orient=\"index\", columns=[\"Target\", \"Predição\"])\n",
    "\n",
    "\n",
    "df_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passivo: 202 acertos, 170 erros\n",
      "Promoter: 39 acertos, 302 erros\n",
      "Detractor: 342 acertos, 25 erros\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Passivo = df_resultado.loc[df_resultado[\"Target\"] == \"Passive\", \"Predição\"]\n",
    "Promoter = df_resultado.loc[df_resultado[\"Target\"] == \"Promoter\", \"Predição\"]\n",
    "Detractor = df_resultado.loc[df_resultado[\"Target\"] == \"Detractor\", \"Predição\"]\n",
    "\n",
    "\n",
    "acerto_passivo = 0\n",
    "erro_passivo = 0\n",
    "acerto_promoter = 0\n",
    "erro_promoter = 0\n",
    "acerto_detrator = 0\n",
    "erro_detrator = 0\n",
    "\n",
    "\n",
    "for idx, predicao in Passivo.items():\n",
    "    if predicao == \"Passive\":\n",
    "        acerto_passivo += 1\n",
    "    else:\n",
    "        erro_passivo += 1\n",
    "\n",
    "for idx, predicao in Promoter.items():\n",
    "    if predicao == \"Promoter\":\n",
    "        acerto_promoter += 1\n",
    "    else:\n",
    "        erro_promoter += 1\n",
    "\n",
    "for idx, predicao in Detractor.items():\n",
    "    if predicao == \"Detractor\":\n",
    "        acerto_detrator += 1\n",
    "    else:\n",
    "        erro_detrator += 1\n",
    "\n",
    "\n",
    "print(f\"Passivo: {acerto_passivo} acertos, {erro_passivo} erros\")\n",
    "print(f\"Promoter: {acerto_promoter} acertos, {erro_promoter} erros\")\n",
    "print(f\"Detractor: {acerto_detrator} acertos, {erro_detrator} erros\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Análise Qualitativa da Performance do Classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando a Acurácia dos Preditores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O total de acertos do classicador das Targets foi de 583\n",
      "\n",
      "O total de erros do classificador de erros das Targets foi de erros totais 497\n",
      "\n",
      "A acurácia do classificador da Target Passive é de 54.30%\n",
      "\n",
      "A acurácia do classificador da Target Detractor é de 93.19%\n",
      "\n",
      "A acurácia do classificador da Target Promoter é de 11.44%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acur_passivo = (acerto_passivo/(acerto_passivo+erro_passivo))*100\n",
    "acur_detractor = (acerto_detrator/(acerto_detrator+erro_detrator))*100\n",
    "acur_promoter = (acerto_promoter/(acerto_promoter+erro_promoter))*100\n",
    "acur_total = ((acur_promoter+acur_detractor+acur_passivo)/3)\n",
    "erros_totais = (erro_passivo+erro_detrator+erro_promoter)\n",
    "acertos_totais = (acerto_passivo+acerto_detrator+acerto_promoter)\n",
    "erros_totais = (erro_passivo+erro_detrator+erro_promoter)\n",
    "acertos_totais = (acerto_passivo+acerto_detrator+acerto_promoter)\n",
    "\n",
    "\n",
    "print(f\"O total de acertos do classicador das Targets foi de {acertos_totais}\")\n",
    "print()\n",
    "print(f\"O total de erros do classificador de erros das Targets foi de erros totais {erros_totais}\")\n",
    "print()\n",
    "print(f\"A acurácia do classificador da Target Passive é de {acur_passivo:.2f}%\")\n",
    "print()\n",
    "print(f\"A acurácia do classificador da Target Detractor é de {acur_detractor:.2f}%\")\n",
    "print()\n",
    "print(f\"A acurácia do classificador da Target Promoter é de {acur_promoter:.2f}%\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do classificador de Target foi de 52.98%\n"
     ]
    }
   ],
   "source": [
    "acur_total = ((acur_promoter+acur_detractor+acur_passivo)/3)\n",
    "\n",
    "\n",
    "print(f\"A acurácia do classificador de Target foi de {acur_total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise da quantidade de palavras nas frases de cada Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASSIVO\n",
    "\n",
    "dic_passivos_test = test.loc[test[\"Target\"]==\"Passive\",\"Review\"]\n",
    "#Transformando em Lista\n",
    "frases_passivos_test = dic_passivos_test.tolist()\n",
    "\n",
    "#Juntando as frases,Limpando (caracteres especiais, e diminuindo as letras)\n",
    "frases_passivos_test = \" \".join(frases_passivos_test)\n",
    "frases_passivos_test = cleanup(frases_passivos_test).lower()\n",
    "frases_passivos_test = frases_passivos_test.split()\n",
    "\n",
    "#Probabilidade de ser Passivo\n",
    "qtd_palavras_passivos_test = pd.Series(frases_passivos_test).value_counts()\n",
    "qtd_palavras_passivos_test = qtd_palavras_passivos_test.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DETRACTOR\n",
    "\n",
    "\n",
    "dic_detrator_test = test.loc[test[\"Target\"]==\"Detractor\",\"Review\"]\n",
    "\n",
    "#Transformando em Lista\n",
    "frases_detractor_test = dic_detrator_test.tolist()\n",
    "#Juntando as frases,Limpando (caracteres especiais, e diminuindo as letras)\n",
    "frases_detractor_test = \" \".join(frases_detractor_test)\n",
    "frases_detractor_test = cleanup(frases_detractor_test).lower()\n",
    "frases_detractor_test = frases_detractor_test.split()\n",
    "\n",
    "#Probabilidade de ser Detrator\n",
    "qtd_palavras_detrator_test = pd.Series(frases_detractor_test).value_counts()\n",
    "qtd_palavras_detrator_test = qtd_palavras_detrator_test.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROMOTER\n",
    "\n",
    "dic_promoter_test = test.loc[test[\"Target\"]==\"Promoter\",\"Review\"]\n",
    "\n",
    "#Transformando em Lista\n",
    "frases_promoter_test = dic_promoter_test.tolist()\n",
    "\n",
    "#Juntando as frases,Limpando (caracteres especiais, e diminuindo as letras)\n",
    "frases_promoter_test = \" \".join(frases_promoter_test)\n",
    "frases_promoter_test = cleanup(frases_promoter_test).lower()\n",
    "frases_promoter_test = frases_promoter_test.split()\n",
    "\n",
    "#Probabilidade de ser Detrator\n",
    "qtd_palavras_promoter_test = pd.Series(frases_promoter_test).value_counts()\n",
    "qtd_palavras_promoter_test = qtd_palavras_promoter_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de palavras de cada frases de Passivos é 49898\n",
      "\n",
      "A quantidade de frases de Detrector é 55514\n",
      "\n",
      "A quantidade de frases de Promoter é 37523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"A quantidade de palavras de cada frases de Passivos é {qtd_palavras_passivos_test}\")\n",
    "print()\n",
    "print(f\"A quantidade de frases de Detrector é {qtd_palavras_detrator_test}\")\n",
    "print()\n",
    "print(f\"A quantidade de frases de Promoter é {qtd_palavras_promoter_test}\")\n",
    "print()\n",
    "\n",
    "#Quantidades parecidas, o que tem melhor acuracia tem mais palavras porem o que tem a segunda maior acuracia tem a menor acuracia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Qualidade do Classificador a partir de novas separações das mensagens entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto\n",
    "\n",
    "Refazendo a Limpeza dos textos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "def cleanup2(text):\n",
    "\n",
    "    text = re.sub(r'http[s]?://\\S+', \"\", text)  \n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)  \n",
    "    text = re.sub(r'\\s+', \" \", text).strip()  \n",
    "    text = text.lower()  \n",
    "\n",
    "    text = re.sub(r\"\\b\\d+\\b\", \"\", text)  \n",
    "\n",
    "    text = \" \".join([word for word in text.split() if len(word) > 2])\n",
    "    \n",
    "    return text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the          0.061173\n",
      "and          0.047007\n",
      "was          0.032424\n",
      "flight       0.017842\n",
      "with         0.014933\n",
      "               ...   \n",
      "meaty        0.000013\n",
      "posting      0.000013\n",
      "screening    0.000013\n",
      "kuldoh       0.000013\n",
      "lhrdohkul    0.000013\n",
      "Name: proportion, Length: 6355, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Descobrindo a quantidade total de palavras\n",
    "dic_total2 = train.loc[:, \"Review\"]  \n",
    "palavras_totais2 = dic_total2.tolist()  \n",
    "palavras_totais2 = \" \".join(palavras_totais2)  \n",
    "palavras_totais2 = cleanup2(palavras_totais2).lower()  \n",
    "palavras_totais2 = palavras_totais2.split()  \n",
    "palavras_totais2 = pd.Series(palavras_totais2)  \n",
    "qtd_palavras_totais2 = palavras_totais2.value_counts()  \n",
    "qtd_palavras_totais2 = qtd_palavras_totais2.sum() \n",
    "\n",
    "\n",
    "#PASSIVO\n",
    "\n",
    "dic_passivos2 = train.loc[train[\"Target\"]==\"Passive\",\"Review\"]\n",
    "#Transformando em Lista\n",
    "frases_passivos2 = dic_passivos2.tolist()\n",
    "\n",
    "#Juntando as frases,Limpando (caracteres especiais, e diminuindo as letras)\n",
    "frases_passivos2 = \" \".join(frases_passivos2)\n",
    "frases_passivos2 = cleanup(frases_passivos2).lower()\n",
    "frases_passivos2 = frases_passivos2.split()\n",
    "\n",
    "#Probabilidade de ser Passivo\n",
    "qtd_palavras_passivos2 = pd.Series(frases_passivos2).value_counts()\n",
    "qtd_palavras_passivos2 = qtd_palavras_passivos2.sum()\n",
    "\n",
    "Prob_Passivo2 = qtd_palavras_passivos2/qtd_palavras_totais2\n",
    "\n",
    "#Criando Frequencia Relativa das Palavras\n",
    "\n",
    "freq_rel_passivos2 = pd.Series(frases_passivos2).value_counts(True)\n",
    "freq_abs_passivos2 = pd.Series(frases_passivos2).value_counts()\n",
    "\n",
    "#DETRACTOR\n",
    "\n",
    "dic_detrator2 = train.loc[train[\"Target\"]==\"Detractor\",\"Review\"]\n",
    "\n",
    "#Transformando em Lista\n",
    "frases_detractor2 = dic_detrator2.tolist()\n",
    "#Juntando as frases,Limpando (caracteres especiais, e diminuindo as letras)\n",
    "frases_detractor2 = \" \".join(frases_detractor2)\n",
    "frases_detractor2 = cleanup2(frases_detractor2).lower()\n",
    "frases_detractor2 = frases_detractor2.split()\n",
    "\n",
    "#Probabilidade de ser Detrator\n",
    "qtd_palavras_detrator2 = pd.Series(frases_detractor2).value_counts()\n",
    "qtd_palavras_detrator2 = qtd_palavras_detrator2.sum()\n",
    "\n",
    "Prob_Detrator2 = qtd_palavras_detrator2/qtd_palavras_totais2\n",
    "\n",
    "#Criando Frequencia Relativa das Palavras\n",
    "\n",
    "freq_rel_detrator2 = pd.Series(frases_detractor2).value_counts(True)\n",
    "freq_abs_detrator2 = pd.Series(frases_detractor2).value_counts()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#PROMOTER\n",
    "\n",
    "dic_promoter2 = train.loc[train[\"Target\"]==\"Promoter\",\"Review\"]\n",
    "\n",
    "#Transformando em Lista\n",
    "frases_promoter2 = dic_promoter2.tolist()\n",
    "\n",
    "#Juntando as frases,Limpando (caracteres especiais, e diminuindo as letras)\n",
    "frases_promoter2 = \" \".join(frases_promoter2)\n",
    "frases_promoter2 = cleanup2(frases_promoter2).lower()\n",
    "frases_promoter2 = frases_promoter2.split()\n",
    "\n",
    "#Probabilidade de ser Detrator\n",
    "qtd_palavras_promoter2 = pd.Series(frases_promoter2).value_counts()\n",
    "qtd_palavras_promoter2 = qtd_palavras_promoter2.sum()\n",
    "\n",
    "Prob_Promoter2 = qtd_palavras_promoter2/qtd_palavras_totais2\n",
    "\n",
    "#Criando Frequencia Relativa das Palavras\n",
    "\n",
    "freq_rel_promoter2 = pd.Series(frases_promoter2).value_counts(True)\n",
    "freq_abs_promoter2 = pd.Series(frases_promoter2).value_counts()\n",
    "\n",
    "print(freq_rel_promoter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificando Performance do Classificador**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Predição</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passive</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Promoter</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Passive</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Passive</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>Passive</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>Passive</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>Passive</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target Predição\n",
       "0       Passive  Passive\n",
       "1     Detractor  Passive\n",
       "2      Promoter  Passive\n",
       "3       Passive  Passive\n",
       "4       Passive  Passive\n",
       "...         ...      ...\n",
       "1075    Passive  Passive\n",
       "1076    Passive  Passive\n",
       "1077  Detractor  Passive\n",
       "1078  Detractor  Passive\n",
       "1079    Passive  Passive\n",
       "\n",
       "[1080 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Codigo da suavização de Laplace\n",
    "\n",
    "dic_final2 = {}\n",
    "Target_test2 = test.loc[:, \"Target\"]\n",
    "Review_test2 = test.loc[:, \"Review\"]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(test)):\n",
    "    tipo2 = Target_test2.iloc[i]  \n",
    "    frase2 = cleanup(Review_test2.iloc[i]).lower().strip()\n",
    "    frase2 = \" \".join(frase2.split())  \n",
    "\n",
    "\n",
    "    probDetratordadoFrase2 = 1\n",
    "    probPassivodadoFrase2 = 1\n",
    "    probPromoterdadoFrase2 = 1\n",
    "\n",
    "    for palavra2 in frase2.split():\n",
    "        palavra2 = palavra2.lower().strip()\n",
    "\n",
    "\n",
    "        if palavra2 in frases_promoter2:\n",
    "            probPromoterdadoFrase2 *= (freq_abs_promoter2[palavra2]+ 1)/(qtd_palavras_promoter2 + qtd_palavras_totais2)  * 1000\n",
    "        else:\n",
    "            probPromoterdadoFrase2 *=(1/(qtd_palavras_promoter2 + qtd_palavras_totais2))  * 1000\n",
    "\n",
    "            \n",
    "        if palavra2 in frases_detractor2:\n",
    "            probDetratordadoFrase2 *= (freq_abs_detrator2[palavra2]+ 1)/(qtd_palavras_detrator2 + qtd_palavras_totais2)   * 1000\n",
    "        else:\n",
    "            probDetratordadoFrase2 *= (1/(qtd_palavras_detrator2 + qtd_palavras_totais2)) * 1000\n",
    "\n",
    "        if palavra2 in frases_passivos2:\n",
    "            probPassivodadoFrase2 *= (freq_abs_passivos2[palavra2]+ 1)/(qtd_palavras_passivos2 + qtd_palavras_totais2)   * 1000\n",
    "        else:\n",
    "            probPassivodadoFrase2 *= (1/(qtd_palavras_passivos2 + qtd_palavras_totais2))  * 1000\n",
    "\n",
    "    maior2 = max(probDetratordadoFrase2, probPromoterdadoFrase2, probPassivodadoFrase2)\n",
    "\n",
    "    if maior2 == probDetratordadoFrase2:\n",
    "        final2 = \"Detractor\"\n",
    "    elif maior2 == probPromoterdadoFrase2:\n",
    "        final2 = \"Promoter\"\n",
    "    else:\n",
    "        final2 = \"Passive\"\n",
    "\n",
    "    dic_final2[i] = (tipo2, final2)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df_resultado2 = pd.DataFrame.from_dict(dic_final2, orient=\"index\", columns=[\"Target\", \"Predição\"])\n",
    "\n",
    "\n",
    "df_resultado2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passivo: 372 acertos, 0 erros\n",
      "Promoter: 0 acertos, 341 erros\n",
      "Detractor: 0 acertos, 367 erros\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Passivo2 = df_resultado2.loc[df_resultado2[\"Target\"] == \"Passive\", \"Predição\"]\n",
    "Promoter2 = df_resultado2.loc[df_resultado2[\"Target\"] == \"Promoter\", \"Predição\"]\n",
    "Detractor2 = df_resultado2.loc[df_resultado2[\"Target\"] == \"Detractor\", \"Predição\"]\n",
    "\n",
    "acerto_passivo2 = 0\n",
    "erro_passivo2 = 0\n",
    "acerto_promoter2 = 0\n",
    "erro_promoter2 = 0\n",
    "acerto_detrator2 = 0\n",
    "erro_detrator2 = 0\n",
    "\n",
    "for idx2, predicao2 in Passivo2.items():\n",
    "    if predicao2 == \"Passive\":\n",
    "        acerto_passivo2 += 1\n",
    "    else:\n",
    "        erro_passivo2 += 1\n",
    "\n",
    "for idx2, predicao2 in Promoter2.items():\n",
    "    if predicao2 == \"Promoter\":\n",
    "        acerto_promoter2 += 1\n",
    "    else:\n",
    "        erro_promoter2 += 1\n",
    "\n",
    "for idx2, predicao2 in Detractor2.items():\n",
    "    if predicao2 == \"Detractor\":\n",
    "        acerto_detrator2 += 1\n",
    "    else:\n",
    "        erro_detrator2 += 1\n",
    "\n",
    "\n",
    "print(f\"Passivo: {acerto_passivo2} acertos, {erro_passivo2} erros\")\n",
    "print(f\"Promoter: {acerto_promoter2} acertos, {erro_promoter2} erros\")\n",
    "print(f\"Detractor: {acerto_detrator2} acertos, {erro_detrator2} erros\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O total de acertos do classicador das Targets foi de 372\n",
      "\n",
      "O total de erros do classificador de erros das Targets foi de erros totais 708\n",
      "\n",
      "A acurácia do classificador da Target Passive é de 100.00%\n",
      "\n",
      "A acurácia do classificador da Target Detractor é de 0.00%\n",
      "\n",
      "A acurácia do classificador da Target Promoter é de 0.00%\n",
      "\n",
      "A acurácia do classificador de Target foi de 33.33%\n"
     ]
    }
   ],
   "source": [
    "acur_passivo2 = (acerto_passivo2/(acerto_passivo2+erro_passivo2))*100\n",
    "acur_detractor2 = (acerto_detrator2/(acerto_detrator2+erro_detrator2))*100\n",
    "acur_promoter2 = (acerto_promoter2/(acerto_promoter2+erro_promoter2))*100\n",
    "acur_total2 = ((acur_promoter2+acur_detractor2+acur_passivo2)/3)\n",
    "erros_totais2 = (erro_passivo2+erro_detrator2+erro_promoter2)\n",
    "acertos_totais2 = (acerto_passivo2+acerto_detrator2+acerto_promoter2)\n",
    "erros_totais2 = (erro_passivo2+erro_detrator2+erro_promoter2)\n",
    "acertos_totais2 = (acerto_passivo2+acerto_detrator2+acerto_promoter2)\n",
    "\n",
    "\n",
    "print(f\"O total de acertos do classicador das Targets foi de {acertos_totais2}\")\n",
    "print()\n",
    "print(f\"O total de erros do classificador de erros das Targets foi de erros totais {erros_totais2}\")\n",
    "print()\n",
    "print(f\"A acurácia do classificador da Target Passive é de {acur_passivo2:.2f}%\")\n",
    "print()\n",
    "print(f\"A acurácia do classificador da Target Detractor é de {acur_detractor2:.2f}%\")\n",
    "print()\n",
    "print(f\"A acurácia do classificador da Target Promoter é de {acur_promoter2:.2f}%\")\n",
    "print()\n",
    "\n",
    "acur_total2 = ((acur_promoter2+acur_detractor2+acur_passivo2)/3)\n",
    "\n",
    "\n",
    "print(f\"A acurácia do classificador de Target foi de {acur_total2:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Leia atentamente a rubrica colocada no enunciado do Projeto 1 (última página). <br>\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nas mensagens, mas tendem a melhorar na classificação das mensagens. Ex: stemming, lemmatization, stopwords.\n",
    "* CONSIDEROU arquivo com três categorias na classificação das variáveis (OBRIGATÓRIO PARA QUARTETOS, sem contar como item avançado)\n",
    "* CONSTRUIU o cálculo das probabilidades corretamente utilizando bigramas E apresentou referência sobre o método utilizado.\n",
    "* EXPLICOU porquê não pode usar novas mensagens classificadas pelo próprio classificador como amostra de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários diferentes, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* REFLETE criticamente sobre os resultados obtidos, identificando limitações do modelo e sugerindo possíveis melhorias ou diferentes abordagens com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa).\n",
    "* DOCUMENTOU bem o código, com explicações claras para cada etapa do processo, incluindo o raciocínio por trás das decisões de modelagem e das transformações de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[Natural Language Processing (Part 17)-Laplacian Smoothing](https://medium.com/@Coursesteach/natural-language-processing-part-17-laplacian-smoothing-7d4be71d0ded) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
